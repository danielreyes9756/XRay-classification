{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X-RAY.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3cu9uLpkQsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "e6d83bf3-bd0a-4f9c-f9d8-6eac34efe346"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlRGXMWPdxMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "91c9e87a-1158-4e14-98b2-9753a95fd4d6"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXdmJHyoofC"
      },
      "source": [
        "train = '/content/drive/My Drive/X-RayProject/train'\n",
        "validation = '/content/drive/My Drive/X-RayProject/validation'\n",
        "test = '/content/drive/My Drive/X-RayProject/test' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7IPHGWyoot6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Dropout, Input, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdUCv1Guoo2a"
      },
      "source": [
        "#-------PARAMETERS--------\n",
        "\n",
        "height=224 #height equals to width but if you need to change some of this parameters you can\n",
        "width=224\n",
        "nChannels=1\n",
        "nClasses=3\n",
        "batch_size=16\n",
        "epochs=200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZHm0TGorkDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "998fe04e-efeb-4cf0-c266-1a3cd5d47ccf"
      },
      "source": [
        "#------------DATA AUGMENTATION-----------\n",
        "datagen = ImageDataGenerator (\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "valdatagen = ImageDataGenerator (\n",
        "    rescale=1./255, \n",
        ")\n",
        "train_generator = datagen.flow_from_directory(  \n",
        "        train,                                                          \n",
        "        target_size=(height, width),                                            \n",
        "        batch_size=batch_size,                                                                                                        \n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale')\n",
        "\n",
        "validation_generator = valdatagen.flow_from_directory(  \n",
        "        validation,                                                          \n",
        "        target_size=(height, width),                                            \n",
        "        batch_size=batch_size,                                                                                                        \n",
        "        class_mode='categorical',\n",
        "        color_mode='grayscale')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6651 images belonging to 4 classes.\n",
            "Found 1459 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VydAdR32tqSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66874408-c37d-4d21-b44e-05b61b7e4781"
      },
      "source": [
        "# MODEL --------------------------------------------------\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(width, height, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu')) \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# TRAINING --------------------------------------------------\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        epochs=epochs,\n",
        "        validation_data = validation_generator,\n",
        "        callbacks = [es]\n",
        ")\n",
        "\n",
        "# SAVING --------------------------------------------------\n",
        "\n",
        "model.save(\"x-ray.h1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "416/416 [==============================] - 2834s 7s/step - loss: 0.8222 - accuracy: 0.6473 - val_loss: 0.8211 - val_accuracy: 0.6875\n",
            "Epoch 2/200\n",
            "416/416 [==============================] - 255s 613ms/step - loss: 0.5838 - accuracy: 0.7673 - val_loss: 0.7247 - val_accuracy: 0.7176\n",
            "Epoch 3/200\n",
            "416/416 [==============================] - 254s 610ms/step - loss: 0.4826 - accuracy: 0.8155 - val_loss: 0.4971 - val_accuracy: 0.8273\n",
            "Epoch 4/200\n",
            "416/416 [==============================] - 255s 613ms/step - loss: 0.4303 - accuracy: 0.8444 - val_loss: 0.6069 - val_accuracy: 0.7656\n",
            "Epoch 5/200\n",
            "416/416 [==============================] - 259s 622ms/step - loss: 0.4017 - accuracy: 0.8540 - val_loss: 0.5701 - val_accuracy: 0.7649\n",
            "Epoch 6/200\n",
            "416/416 [==============================] - 257s 618ms/step - loss: 0.3676 - accuracy: 0.8618 - val_loss: 0.5516 - val_accuracy: 0.8088\n",
            "Epoch 7/200\n",
            "416/416 [==============================] - 255s 613ms/step - loss: 0.3419 - accuracy: 0.8714 - val_loss: 0.5980 - val_accuracy: 0.7676\n",
            "Epoch 8/200\n",
            "416/416 [==============================] - 255s 614ms/step - loss: 0.3204 - accuracy: 0.8803 - val_loss: 0.4274 - val_accuracy: 0.8376\n",
            "Epoch 9/200\n",
            "416/416 [==============================] - 262s 629ms/step - loss: 0.3208 - accuracy: 0.8830 - val_loss: 0.4218 - val_accuracy: 0.8376\n",
            "Epoch 10/200\n",
            "416/416 [==============================] - 261s 627ms/step - loss: 0.3081 - accuracy: 0.8886 - val_loss: 0.3962 - val_accuracy: 0.8547\n",
            "Epoch 11/200\n",
            "416/416 [==============================] - 258s 621ms/step - loss: 0.3162 - accuracy: 0.8844 - val_loss: 0.3931 - val_accuracy: 0.8746\n",
            "Epoch 12/200\n",
            "416/416 [==============================] - 258s 620ms/step - loss: 0.2720 - accuracy: 0.9023 - val_loss: 0.3855 - val_accuracy: 0.8622\n",
            "Epoch 13/200\n",
            "416/416 [==============================] - 257s 617ms/step - loss: 0.2613 - accuracy: 0.9059 - val_loss: 1.2300 - val_accuracy: 0.6484\n",
            "Epoch 14/200\n",
            "416/416 [==============================] - 256s 614ms/step - loss: 0.2745 - accuracy: 0.9032 - val_loss: 0.3720 - val_accuracy: 0.8622\n",
            "Epoch 15/200\n",
            "416/416 [==============================] - 257s 619ms/step - loss: 0.2527 - accuracy: 0.9092 - val_loss: 0.3678 - val_accuracy: 0.8650\n",
            "Epoch 16/200\n",
            "416/416 [==============================] - 256s 617ms/step - loss: 0.2630 - accuracy: 0.9066 - val_loss: 0.3057 - val_accuracy: 0.8828\n",
            "Epoch 17/200\n",
            "416/416 [==============================] - 257s 617ms/step - loss: 0.2497 - accuracy: 0.9092 - val_loss: 0.3670 - val_accuracy: 0.8595\n",
            "Epoch 18/200\n",
            "416/416 [==============================] - 254s 610ms/step - loss: 0.2415 - accuracy: 0.9132 - val_loss: 0.4538 - val_accuracy: 0.8334\n",
            "Epoch 19/200\n",
            "416/416 [==============================] - 257s 617ms/step - loss: 0.2360 - accuracy: 0.9175 - val_loss: 0.3459 - val_accuracy: 0.8869\n",
            "Epoch 20/200\n",
            "416/416 [==============================] - 254s 611ms/step - loss: 0.2181 - accuracy: 0.9254 - val_loss: 0.3627 - val_accuracy: 0.8739\n",
            "Epoch 21/200\n",
            "416/416 [==============================] - 255s 613ms/step - loss: 0.2263 - accuracy: 0.9191 - val_loss: 0.2803 - val_accuracy: 0.8931\n",
            "Epoch 22/200\n",
            "416/416 [==============================] - 256s 614ms/step - loss: 0.2250 - accuracy: 0.9157 - val_loss: 0.3654 - val_accuracy: 0.8588\n",
            "Epoch 23/200\n",
            "416/416 [==============================] - 260s 626ms/step - loss: 0.2119 - accuracy: 0.9226 - val_loss: 0.2927 - val_accuracy: 0.8979\n",
            "Epoch 24/200\n",
            "416/416 [==============================] - 260s 624ms/step - loss: 0.2068 - accuracy: 0.9229 - val_loss: 0.3349 - val_accuracy: 0.8897\n",
            "Epoch 25/200\n",
            "416/416 [==============================] - 257s 617ms/step - loss: 0.2174 - accuracy: 0.9256 - val_loss: 0.3140 - val_accuracy: 0.8862\n",
            "Epoch 26/200\n",
            "416/416 [==============================] - 259s 622ms/step - loss: 0.2115 - accuracy: 0.9199 - val_loss: 0.3275 - val_accuracy: 0.8801\n",
            "Epoch 27/200\n",
            "416/416 [==============================] - 262s 630ms/step - loss: 0.2148 - accuracy: 0.9223 - val_loss: 0.3996 - val_accuracy: 0.8663\n",
            "Epoch 28/200\n",
            "416/416 [==============================] - 261s 628ms/step - loss: 0.2123 - accuracy: 0.9266 - val_loss: 0.4169 - val_accuracy: 0.8691\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: x-ray.h1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}